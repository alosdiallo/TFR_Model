---
title: "R Notebook"
output:
  pdf_document: default
  html_notebook: default
---

Here is my toolbox for the project.
```{r}
library(neuralnet)
library(readxl)
library(grid)
library(corrplot)
library(caret)
library(e1071)
library(ROCR)
library(ggplot2)
library(GGally)
library(PerformanceAnalytics)
library(factoextra)
library(corrplot)
library(Rtsne)
library(FactoMineR)
library(ggplot2)
library(factoextra)
library(survminer)
library(ggcorrplot)
library(readr)
library(circlize)
library(readxl)
library(stringr)
library(reshape)
library(psych)
library(ComplexHeatmap)
library(ggpubr)
library(readr)
library(gridExtra)
library(cowplot)
library(MASS)
library(fitdistrplus)
#BiocManager::install("preprocessCore")
library(preprocessCore)
library(MASS)
library(class)
library(ggplot2)
library(reshape2)
library(ROCR)
library(e1071)
library(GGally)
library(klaR)
library(randomForest)
```

```{r}
model_4_21_95wRAW = NULL
model_4_21_95wRAW <- read_excel("/Users/adiallo/Desktop/model_4_21_95wRAW.xlsx")
```

```{r}
summPreds <- function(inpPred,inpTruth,inpMetrNms=c("err","acc","sens","spec")) {
  retVals <- numeric()
  for ( metrTmp in inpMetrNms ) {
    retVals[metrTmp] <- performance(prediction(inpPred,inpTruth),measure=metrTmp)@y.values[[1]][2]
  }
  retVals
}
```





```{r}
dim(model_4_21_95wRAW)
multi.hist(model_4_21_95wRAW[,2:44]) 
#pairs(model_4_21_95wRAW[,2:44])
```


PCA
```{r}



#here we are computing PCA

prcompTmp <- prcomp(model_4_21_95wRAW[,2:44],center = TRUE,scale = TRUE)

#Here we have a plot of the variance by principle componant
plot(prcompTmp)

#This is just a fancy way of doing the same thing
fviz_eig(prcompTmp, addlabels=TRUE, ylim=c(0,60), geom = c("bar", "line"), barfill = "gold", barcolor="grey",linecolor = "red", ncp=10)+
labs(title = "Principal Component Analysis Immune Cell Data",
         x = "Principal Components", y = "% of variances")


all_var <- get_pca_var(prcompTmp)
all_var

#Correlation between variables and PCA
#It shows the importance of a principal component for a given observation (vector of original variables). You can go through the following link for details.
corrplot(all_var$cos2, is.corr=FALSE)

#To highlight the most contributing variables for each components
corrplot(all_var$contrib, is.corr=FALSE)    
# 
pdf("cor_plots.pdf")
corrplot(all_var$contrib, is.corr=FALSE) 
dev.off()

fviz_pca_var(prcompTmp, col.var = "black")


fviz_pca_var(prcompTmp, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE # Avoid text overlapping
             )




```

Test area for models
```{r}
    Train = NULL
    Test = NULL
    bTrain = sample(1:nrow(model_4_21_95wRAW),round(0.7*nrow(model_4_21_95wRAW)))
    Train <- model_4_21_95wRAW[bTrain,2:45]
    Test <- model_4_21_95wRAW[-bTrain,2:45]
    Test = as.data.frame(Test)
              Train$cat = as.numeric(as.factor(Train$cat))
          Test$cat = as.numeric(as.factor(Test$cat))
   dfTmp <- NULL 
   iResample = 1

        # KNN:
        for ( kTmp in c(10,20,150,300) ) {

      knnTestPred <- knn(Train[,2:44],Test[,2:44],Train$cat,k=kTmp)
      tmpVals <- summPreds(as.numeric(knnTestPred),as.numeric(Test$cat))
      dfTmp <- rbind(dfTmp,data.frame(resample=c("Validation","Bootstrap")[iResample],type=paste0("K",kTmp),metric=names(tmpVals),value=tmpVals))
}

```



Here is the validation code set.  Right now I am only using a few models but ideally I would include more.

```{r testerr,warning=FALSE}
# warning=FALSE in knitr clause prevents well understood warnings from cluttering the output
dfTmp <- NULL
for ( iResample in 1:2 ) {
  for ( iSim in 1:100 ) {
    bTrain = sample(1:nrow(model_4_21_95wRAW),round(0.7*nrow(model_4_21_95wRAW)))
    Train <- model_4_21_95wRAW[bTrain,2:45]
    Test <- model_4_21_95wRAW[-bTrain,2:45]
    Test = as.data.frame(Test)
    Train = as.data.frame(Train)
    if ( iResample == 2 ) {
          bTrain = sample(1:nrow(model_4_21_95wRAW),round(0.7*nrow(model_4_21_95wRAW)),replace=TRUE)
    Train <- model_4_21_95wRAW[bTrain,2:45]
    Test <- model_4_21_95wRAW[-bTrain,2:45]
    Test = as.data.frame(Test)
    Train = as.data.frame(Train)
    }
    # logistic regression:
  glmTrain <- glm(as.factor(Train$cat)~.,data=Train[,2:44],family=binomial)
  glmTestPred <- predict(glmTrain, newdata=Test[,2:44], type="response") > 0.5
  tmpVals <- summPreds(as.numeric(glmTestPred)+1,as.factor(Test$cat))
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Validation","Bootstrap")[iResample],type="LR",metric=names(tmpVals),value=tmpVals))
#RF
Y = factor(as.numeric(as.factor(Train$cat)))
rfTmp <- randomForest(Y~.,data=Train[,2:44],mTry = 10)
rfTestPred <- predict(rfTmp,newdata=Test)
mseTest <- mean((as.numeric(factor(Test$cat))-as.numeric(rfTestPred))) #Calculating the mean squared error
tmpVals <- summPreds(as.numeric(factor(Test$cat)),as.numeric(rfTestPred))
dfTmp <- rbind(dfTmp,data.frame(resample=c("Validation","Bootstrap")[iResample],type="RF",metric=names(tmpVals),value=tmpVals))
# LDA:
ldaTrain <- lda(Train$cat~.,data=Train[,2:44])
ldaTestPred <- predict(ldaTrain, newdata=Test[,2:44])
tmpVals <- summPreds(as.numeric(ldaTestPred$class),as.factor(Test$cat))
dfTmp <- rbind(dfTmp,data.frame(resample=c("Validation","Bootstrap")[iResample],type="LDA",metric=names(tmpVals),value=tmpVals))
# NB:
Y = factor(as.numeric(as.factor(Train$cat)))
nbTrain <- naiveBayes(Y~.,data=Train[,2:44])
nbTestPred = predict(nbTrain, newdata=Test[,2:44])
tmpVals = summPreds(as.numeric(nbTestPred),as.numeric(as.factor(Test$cat)))
dfTmp <- rbind(dfTmp,data.frame(resample=c("Validation","Bootstrap")[iResample],type="NB",metric=names(tmpVals),value=tmpVals))

  }
}
```


```{r}
p = ggplot(dfTmp,aes(x=type,y=100*value,colour = type)) + geom_boxplot(fill="white") + geom_point() + facet_wrap(~resample+metric,ncol=4,scales="free") + xlab("") + ylab("") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme_bw()
#png("/Users/adiallo/Desktop/model/test2.png",width = 40,height = 40,units = "in",res= 120,pointsize = 12)
p
```




```{r}
x <- 1:10
cor(x,x^2)
cor(scale(x),scale(x)^2)



a = -4
b = sqrt(a)
b

```







