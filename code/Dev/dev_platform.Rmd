---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 
```{r message=FALSE, include=FALSE}
library(grid)
library(corrplot)
library(caret)
library(e1071)
library(ROCR)
library(ggplot2)
library(GGally)
library(PerformanceAnalytics)
library(factoextra)
library(corrplot)
library(Rtsne)
library(FactoMineR)
library(ggplot2)
library(factoextra)
library(survminer)
library(ggcorrplot)
library(readr)
library(circlize)
library(readxl)
library(stringr)
library(reshape)
library(psych)
library(ComplexHeatmap)
library(ggpubr)
library(readr)
library(gridExtra)
library(cowplot)
library(MASS)
library(fitdistrplus)
#BiocManager::install("preprocessCore")
library(preprocessCore)
library(MASS)
library(class)
library(ggplot2)
library(reshape2)
library(ROCR)
library(e1071)
library(GGally)
library(klaR)
library(randomForest)
```



```{r}
summPreds <- function(inpPred,inpTruth,inpMetrNms=c("err","acc","sens","spec")) {
  retVals <- numeric()
  for ( metrTmp in inpMetrNms ) {
    retVals[metrTmp] <- performance(prediction(inpPred,inpTruth),measure=metrTmp)@y.values[[1]][2]
  }
  retVals
}
```

Don't use
```{r}

library(readxl)
model <- read_excel("C:/Users/Alos Diallo/Documents/GitHub/TFR_Model/Data/Training_Test_Set.xlsx")

dim(model)
size = ncol(model) -1


dfTmpLR <- NULL
dfTmpRF <- NULL
dfTmpNB <- NULL
dfTmpLDA <- NULL
dfTmpSVM <- NULL
dfTmp = NULL
svmTuneRes = NULL
Train = NULL
Test = NULL
dfTmpKNN = NULL


  bTrain = sample(1:nrow(model),round(0.7*nrow(model)))
  Train <- model[bTrain,]
  Test <- model[-bTrain,]
  Test = as.data.frame(Test)
  Train$cat = as.numeric(as.factor(Train$cat))
  Test$cat = as.numeric(as.factor(Test$cat))



  #SVM Test Error:
  svmResult = svm(Train$cat~.,data=Train[,2:size],kernel="linear",scale = FALSE) 
  
  
  svmTestPred = predict(svmResult, newdata=Test[,2:size])
  tmpVals = summPreds(predict(svmResult,newdata=Train[,2:size],scale = FALSE),Train$cat)
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Train"),type="SVM",metric=names(tmpVals),value=tmpVals))
  tmpVals

        

```

Current code
```{r warning=FALSE}

library(readxl)
model <- read_excel("C:/Users/Alos Diallo/Documents/GitHub/TFR_Model/Data/Training_Test_Set.xlsx")

for ( iSim in 1:100 ) {
dfTmpLR <- NULL
dfTmpRF <- NULL
dfTmpNB <- NULL
dfTmpLDA <- NULL
dfTmpSVM <- NULL
dfTmp = NULL
svmTuneRes = NULL
Train = NULL
Test = NULL
dfTmpKNN = NULL

cols_to_use = 14:78
bTrain = sample(1:nrow(model),round(0.7*nrow(model)))
model2 = model[,c(1,cols_to_use,79)]
dim(model2)
size = ncol(model2) 

Train <- model2[bTrain,]
Test <- model2[-bTrain,]
Test = as.data.frame(Test)
Train$cat = as.numeric(as.factor(Train$cat))
Test$cat = as.numeric(as.factor(Test$cat))
  

  # Changed logistic regression Test error:
  glmTrain <- glm(as.factor(cat)~.,data=Train[,2:size],family=binomial)
  glmTestPred <- predict(glmTrain, newdata=Test[,2:size], type="response") > 0.5
  tmpVals <- summPreds(as.numeric(glmTestPred)+1,as.factor(Test$cat))
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Test"),type="LR",metric=names(tmpVals),value=tmpVals))

  # Changed logistic regression Training Error:
  glmTrain <- glm(as.factor(cat)~.,data=Train[,2:size],family=binomial)
  tmpVals <- summPreds(as.numeric(predict(glmTrain,type="response") > 0.5)+1,as.factor(Train$cat))
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Train"),type="LR",metric=names(tmpVals),value=tmpVals))
  
  # Changed LDA Training Error:
  ldaTrain <- lda(cat~.,data=Train[,2:size],cv = TRUE)
  ldaTestPred <- predict(ldaTrain, newdata=Train[,2:size])
  tmpVals <- summPreds(as.numeric(ldaTestPred$class),as.factor(Train$cat))
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Train"),type="LDA",metric=names(tmpVals),value=tmpVals))
  
  # Changed LDA Test Error:
  ldaTrain <- lda(cat~.,data=Train[,2:size])
  ldaTestPred <- predict(ldaTrain, newdata=Test[,2:size])
  tmpVals <- summPreds(as.numeric(ldaTestPred$class),as.factor(Test$cat))
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Test"),type="LDA",metric=names(tmpVals),value=tmpVals))
  
  # Changed NB Training Error:
  Data_log_transformed = log(Train[,2:size] + 1)
  nbTrain <- naiveBayes(cat~.,data=Data_log_transformed)
  nbTrainPred = predict(nbTrain, newdata=Data_log_transformed)
  tmpVals = summPreds(as.numeric(nbTrainPred),Train$cat)
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Train"),type="NB",metric=names(tmpVals),value=tmpVals))
  
  # Changed NB Test Error:
  Test_Data_log_transformed = log(Test[,2:size] + 1)
  nbTrain <- naiveBayes(cat~.,data=Data_log_transformed)
  nbTestPred = predict(nbTrain, newdata=Test_Data_log_transformed)
  tmpVals = summPreds(as.numeric(nbTestPred),Test$cat)
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Test"),type="NB",metric=names(tmpVals),value=tmpVals))
  
  # changed SVM Test Error:
  svmResult = svm(factor(cat)~.,data=Train[,2:size],kernel="linear",cost = 1e+02) 
  svmTestPred = predict(svmResult, newdata=Test[,2:size])
  tmpVals = summPreds(as.numeric(predict(svmResult,newdata=Test[,2:size])),Test$cat)
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Test"),type="SVM",metric=names(tmpVals),value=tmpVals))
  
  # changed SVM Training Error:
  svmResult = svm(factor(cat)~.,data=Train[,2:size],kernel="linear",cost = 1e+02) 
  svmTestPred = predict(svmResult, newdata=Test[,2:size])
  tmpVals = summPreds(as.numeric(predict(svmResult,newdata=Train[,2:size])),Train$cat)
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Train"),type="SVM",metric=names(tmpVals),value=tmpVals))
  
  # changed RF Test Error:
  rfTmp <- randomForest(factor(cat)~.,data=Train[,2:size],mTry = 10)
  rfTestPred <- predict(rfTmp,newdata=Test)
  tmpVals <- summPreds(as.numeric(Test$cat),as.numeric(rfTestPred))
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Test"),type="RF",metric=names(tmpVals),value=tmpVals))
  
  # changed RF Training Error:
  rfTmp <- randomForest(factor(cat)~.,data=Train[,2:size],mTry = 10)
  rfTrainPred <- predict(rfTmp, newdata=Train[,2:size])
  tmpVals <- summPreds(as.numeric(rfTrainPred),Train$cat)
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Train"),type="RF",metric=names(tmpVals),value=tmpVals))
  
  # changed KNN Test Error:
  for ( kTmp in c(10,20,150,300) ) {
  knnTestPred <- knn(Train[,2:size],Test[,2:size],factor(Train$cat),k=kTmp)
  tmpVals <- summPreds(as.numeric(knnTestPred),as.numeric(Test$cat))
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Test"),type="KNN",metric=names(tmpVals),value=tmpVals))
  }
  
  # changed KNN Training Error:
  for ( kTmp in c(10,20,150,300) ) {
  knnTrainPred <- knn(Train[,2:size],Train[,2:size],factor(Train$cat),k=kTmp)
  tmpVals <- summPreds(as.numeric(knnTrainPred),as.numeric(Train$cat))
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Train"),type="KNN",metric=names(tmpVals),value=tmpVals))
  }
  
  
}

```





Here we have the performance metrics for each model.
```{r}
p = NULL
p = ggplot(dfTmp,aes(x=type,y=100*value,colour = type)) + geom_boxplot(fill="white") + geom_point() + facet_wrap(~resample+metric,ncol=4,scales="free") + xlab("") + ylab("") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + theme_bw()

p
```




```{r}
for ( iSim in 1:40 ) {
dfTmpLR <- NULL
dfTmpRF <- NULL
dfTmpNB <- NULL
dfTmpLDA <- NULL
dfTmpSVM <- NULL
dfTmp = NULL
svmTuneRes = NULL
Train = NULL
Test = NULL
dfTmpKNN = NULL

cols_to_use = 14:78
bTrain = sample(1:nrow(model),round(0.7*nrow(model)))
model2 = model[,c(1,cols_to_use,79)]
dim(model2)
size = ncol(model2) 

Train <- model2[bTrain,]
Test <- model2[-bTrain,]
Test = as.data.frame(Test)
Train$cat = as.numeric(as.factor(Train$cat))
Test$cat = as.numeric(as.factor(Test$cat))

  # logistic regression Test error:
  glmTrain <- glm(as.factor(cat)~.,data=Train[,2:size],family=binomial)
  glmTestPred <- predict(glmTrain, newdata=Test[,2:size], type="response") > 0.5
  tmpVals <- summPreds(as.numeric(glmTestPred)+1,as.factor(Test$cat))
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Test"),type="LR",metric=names(tmpVals),value=tmpVals))

  # logistic regression Training Error:
  glmTrain <- glm(as.factor(cat)~.,data=Train[,2:size],family=binomial)
  tmpVals <- summPreds(as.numeric(predict(glmTrain,type="response") > 0.5) +1,as.factor(Train$cat))
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Train"),type="LR",metric=names(tmpVals),value=tmpVals))
  
  #SVM Test Error:
  svmResult = svm(factor(cat)~.,data=Train[,2:size],kernel="linear",cost = 1e+02) 
  svmTestPred = predict(svmResult, newdata=Test[,2:size])
  tmpVals = summPreds(as.numeric(predict(svmResult,newdata=Test[,2:size])),Test$cat)
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Test"),type="SVM",metric=names(tmpVals),value=tmpVals))
  tmpVals
  
  #SVM Training Error:
  svmResult = svm(factor(cat)~.,data=Train[,2:size],kernel="linear",cost = 1e+02) 
  svmTestPred = predict(svmResult, newdata=Test[,2:size])
  tmpVals = summPreds(as.numeric(predict(svmResult,newdata=Train[,2:size])),Train$cat)
  dfTmp <- rbind(dfTmp,data.frame(resample=c("Train"),type="SVM",metric=names(tmpVals),value=tmpVals))
  
}
```




```{r}
  

v = log(Train[,2:size] + 1)
  nbTrain <- naiveBayes(cat~.,data=v)
  nbTrainPred = predict(nbTrain, newdata=v)
  tmpVals = summPreds(as.numeric(nbTrainPred),Train$cat)
  
  
  
```

